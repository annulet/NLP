{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ –∏–∑ 2-—Ö —á–∞—Å—Ç–µ–π.\n",
    "–ë–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ (–∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è)\n",
    "1. –£—á–∏–º conv —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –≤—ã–±–∏—Ç—å auc –≤—ã—à–µ 0.95\n",
    "2. –ü—Ä–µ–¥–æ–±—É—á–∞–µ–º word2vec –∏ –µ–≥–æ —ç–º–±–µ–¥–∏–Ω–≥–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ç–∫—É, –∫–∞–∫ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ –æ–∫!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∫—Ä–æ–º–µ —Ç–æ–≥–æ —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ–ª—å...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>–ù–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ gps, sms, –∑–≤–æ–Ω–∫–∞–º –∏ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–¥–≤–∏—Å–∞–Ω–∏...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–∞—è —à—Ç—É–∫–∞</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>–£–¥–æ–±–Ω–æ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –¥–ª—è –æ–ø–ª–∞—Ç—ã –ø–ª–∞—Ç–µ–∂–µ–π ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>–£–¥–æ–±–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating                                            Content        Date\n",
       "0        5                                     It just works!  2017-08-14\n",
       "1        4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2        5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3        5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4        5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5        5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6        5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7        5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8        5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9        5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14\n",
       "10       5                                            –í—Å–µ –æ–∫!  2017-08-14\n",
       "11       5  –í—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∫—Ä–æ–º–µ —Ç–æ–≥–æ —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ–ª—å...  2017-08-14\n",
       "12       2  –ù–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ gps, sms, –∑–≤–æ–Ω–∫–∞–º –∏ ...  2017-08-14\n",
       "13       5  –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–¥–≤–∏—Å–∞–Ω–∏...  2017-08-14\n",
       "14       5                                       –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ  2017-08-14\n",
       "15       5                                –û—á–µ–Ω—å —É–¥–æ–±–Ω–∞—è —à—Ç—É–∫–∞  2017-08-14\n",
       "16       5                                –û—Ç–ª–∏—á–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ  2017-08-14\n",
       "17       5                                   –£–¥–æ–±–Ω–æ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ  2017-08-14\n",
       "18       5  –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –¥–ª—è –æ–ø–ª–∞—Ç—ã –ø–ª–∞—Ç–µ–∂–µ–π ...  2017-08-14\n",
       "19       5                                    –£–¥–æ–±–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ  2017-08-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub('https?://\\S+|www\\.\\S+', ' ', txt)\n",
    "    txt = re.sub(r'\\)+', ' –≤–µ—Å–µ–ª—ã–π', txt)\n",
    "    txt = re.sub(r'\\(+', ' –≥—Ä—É—Å—Ç–Ω—ã–π', txt)\n",
    "    txt = re.sub(r'[^\\w\\s]',' ', txt)\n",
    "    txt = re.sub(r'[0-9]+', ' ', txt)\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    txt = re.sub(\"–Ω–µ\\s\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in stop_words]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "data['text'] = data['Content'].apply(preprocess_text)\n",
    "data = data[data['Rating'] != 3]\n",
    "data['target'] = data['Rating'] > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>it just works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å—à–æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>–æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>–∑–∞–≤–∏—Å–∞—Ç—å —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14   \n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14   \n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14   \n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14   \n",
       "\n",
       "                                                text  target  \n",
       "0                                      it just works       1  \n",
       "1  —Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å—à–æ...       1  \n",
       "2                                            –æ—Ç–ª–∏—á–Ω–æ       1  \n",
       "3  –∑–∞–≤–∏—Å–∞—Ç—å —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω...       1  \n",
       "4                             —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['target'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data['text'], data['target'], test_size=0.2,\n",
    "                                                    random_state=13, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7986\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)  \n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "(15798, 130)\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, padding='post')\n",
    "print(X_train[0])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_val = pad_sequences(X_val, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = X_train.shape[0]\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          255584    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         20608     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 280,353\n",
      "Trainable params: 280,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word_index)+1\n",
    "EMBEDDING_DIM = 32\n",
    "WEIGHT_DECAY = 0.001\n",
    "wd = tf.keras.regularizers.l2(WEIGHT_DECAY)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu', kernel_regularizer=wd),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 0.4433 - accuracy: 0.8526 - val_loss: 0.3010 - val_accuracy: 0.8866\n",
      "Epoch 2/15\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.2956 - accuracy: 0.8950 - val_loss: 0.2506 - val_accuracy: 0.9018\n",
      "Epoch 3/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2530 - accuracy: 0.9120 - val_loss: 0.2424 - val_accuracy: 0.9101\n",
      "Epoch 4/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2341 - accuracy: 0.9214 - val_loss: 0.2212 - val_accuracy: 0.9137\n",
      "Epoch 5/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2167 - accuracy: 0.9269 - val_loss: 0.2143 - val_accuracy: 0.9157\n",
      "Epoch 6/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2035 - accuracy: 0.9320 - val_loss: 0.2111 - val_accuracy: 0.9165\n",
      "Epoch 7/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1906 - accuracy: 0.9362 - val_loss: 0.2097 - val_accuracy: 0.9187\n",
      "Epoch 8/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1826 - accuracy: 0.9411 - val_loss: 0.2046 - val_accuracy: 0.9192\n",
      "Epoch 9/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1701 - accuracy: 0.9451 - val_loss: 0.2072 - val_accuracy: 0.9203\n",
      "Epoch 10/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1621 - accuracy: 0.9478 - val_loss: 0.2003 - val_accuracy: 0.9238\n",
      "Epoch 11/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1516 - accuracy: 0.9525 - val_loss: 0.2035 - val_accuracy: 0.9238\n",
      "Epoch 12/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1412 - accuracy: 0.9572 - val_loss: 0.2110 - val_accuracy: 0.9263\n",
      "Epoch 13/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1343 - accuracy: 0.9614 - val_loss: 0.2070 - val_accuracy: 0.9263\n",
      "Epoch 14/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1235 - accuracy: 0.9628 - val_loss: 0.2106 - val_accuracy: 0.9261\n",
      "Epoch 15/15\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1196 - accuracy: 0.9646 - val_loss: 0.2192 - val_accuracy: 0.9268\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 15\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=num_epochs, \n",
    "    validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
