{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тема “Создание признакового пространства” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1. \n",
    "\n",
    "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000) \n",
    "\n",
    "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор? \n",
    "\n",
    "Повторим шаги из заданий 1 и 2, используя библиотеку nltk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = pd.read_pickle('processed_df.pkl')\n",
    "processed_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wheelchair vans</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdx</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the next school year</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word     ner\n",
       "0       wheelchair vans     ORG\n",
       "1                   pdx     ORG\n",
       "2                bihday  PERSON\n",
       "3              tomorrow    DATE\n",
       "4  the next school year    DATE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "processed_df['NER'] = processed_df['clean_tweet'].apply(lambda x:  nlp(x))\n",
    "\n",
    "ner = processed_df['NER'].tolist()\n",
    "\n",
    "NER = []\n",
    "for doc in ner:\n",
    "    for ent in doc.ents:\n",
    "        NER.append((ent.text, ent.label_))\n",
    "\n",
    "df_ner = pd.DataFrame(NER, columns=['word', 'ner'])\n",
    "df_ner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ТОП-20 популярных NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE           11507\n",
       "PERSON          8040\n",
       "ORG             5575\n",
       "GPE             4570\n",
       "TIME            2021\n",
       "NORP            1448\n",
       "CARDINAL        1098\n",
       "ORDINAL          647\n",
       "FAC              303\n",
       "LOC              216\n",
       "EVENT            151\n",
       "PRODUCT           63\n",
       "LANGUAGE          43\n",
       "QUANTITY          34\n",
       "WORK_OF_ART       27\n",
       "LAW               21\n",
       "MONEY              8\n",
       "PERCENT            3\n",
       "Name: ner, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_ner = df_ner.ner.value_counts().head(20)\n",
    "top_20_ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Топ-20 персон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hea                                                        116\n",
       "hu                                                          83\n",
       "blur sun                                                    54\n",
       "bihday                                                      46\n",
       "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
       "christina grimmie                                           38\n",
       "hillary                                                     36\n",
       "sikh temple                                                 28\n",
       "tgif ff                                                     26\n",
       "don                                                         24\n",
       "detoxdiet altwaystoheal                                     21\n",
       "clinton                                                     21\n",
       "jo cox                                                      20\n",
       "ripchristina                                                20\n",
       "carl paladino                                               19\n",
       "regrann                                                     17\n",
       "karen iqbal                                                 17\n",
       "donald trump                                                16\n",
       "michelle                                                    15\n",
       "anton yelchin                                               15\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_pers = df_ner.loc[df_ner['ner'] == 'PERSON']\n",
    "\n",
    "top_20_pers = top_20_pers.word.value_counts().head(20)\n",
    "top_20_pers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тот-20 организаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bong bing           107\n",
       "app                  84\n",
       "gop                  77\n",
       "islam                58\n",
       "house                46\n",
       "social analytics     40\n",
       "nba                  39\n",
       "usa                  34\n",
       "amazon               32\n",
       "sta                  31\n",
       "sma                  30\n",
       "cnn                  28\n",
       "euro                 26\n",
       "fed                  25\n",
       "ios                  23\n",
       "eu                   22\n",
       "fbi                  21\n",
       "bogota colombia      20\n",
       "sun                  20\n",
       "congress             19\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_org = df_ner.loc[df_ner['ner'] == 'ORG']\n",
    "\n",
    "top_20_org = top_20_org.word.value_counts().head(20)\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2. \n",
    "\n",
    "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру. \n",
    "\n",
    "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [(when, WRB), (father, NN), (is, VBZ), (dysfun...\n",
       "1    [(thanks, NNS), (for, IN), (lyft, JJ), (credit...\n",
       "2          [(bihday, RB), (your, PRP$), (majesty, NN)]\n",
       "3    [(model, NN), (love, NN), (yoyou, NNS), (take,...\n",
       "4    [(factsguide, JJ), (society, NN), (now, RB), (...\n",
       "Name: tagged, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "processed_df['tagged'] = processed_df['clean_tweet'].apply(\n",
    "    lambda x: nltk.pos_tag(nltk.word_tokenize(x)) \n",
    ")\n",
    "\n",
    "processed_df['tagged'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('when', 'WRB'),\n",
       "  ('father', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('dysfunctional', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('so', 'RB'),\n",
       "  ('selfish', 'JJ'),\n",
       "  ('he', 'PRP'),\n",
       "  ('drags', 'VBZ'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('kids', 'NNS'),\n",
       "  ('into', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('dysfunction', 'NN'),\n",
       "  ('run', 'VB')]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = processed_df['tagged'].tolist()\n",
    "corpus[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('when', 'WRB')\n",
      "('father', 'NN')\n",
      "('is', 'VBZ')\n",
      "('dysfunctional', 'JJ')\n",
      "('and', 'CC')\n",
      "('is', 'VBZ')\n",
      "('so', 'RB')\n",
      "('selfish', 'JJ')\n",
      "('he', 'PRP')\n",
      "('drags', 'VBZ')\n",
      "('his', 'PRP$')\n",
      "('kids', 'NNS')\n",
      "('into', 'IN')\n",
      "('his', 'PRP$')\n",
      "('dysfunction', 'NN')\n",
      "('run', 'VB')\n",
      "Wall time: 89.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sent in corpus:\n",
    "    temp = nltk.ne_chunk(sent)\n",
    "    for i in temp:\n",
    "        print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3. \n",
    "\n",
    "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "я не поняла, почему NLTK не работает("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
